{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Clone the Pristi repository clone \n!git clone https://github.com/LMZZML/PriSTI.git\n\n# Navigate into the directory\n!cd PriSTI\n\n# Install the required packages\n!pip install -r /kaggle/working/PriSTI/requirements.txt\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cd PriSTI\n!pip install -r /kaggle/working/PriSTI/requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working/PriSTI') ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports and paths \nimport os, sys, json, yaml, pickle, numpy as np, pandas as pd, torch\n\n# Paths â€“ adjust if your layout differs\nPRISTI_ROOT = \"/kaggle/working/PriSTI\"\nCONFIG_PATH = f\"{PRISTI_ROOT}/config/base.yaml\"\nWEIGHTS_PATH = f\"{PRISTI_ROOT}/save/aqi36/model.pth\"   # included in your working tree\nMEANSTD_PK = \"/kaggle/input/airq36/pm25/pm25_meanstd.pk\"  # from AQI-36 dataset\n\n# Make PriSTI importable\nsys.path.append(PRISTI_ROOT)\n\nfrom main_model import PriSTI_aqi36","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, shutil\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load config\nwith open(CONFIG_PATH, \"r\") as f:\n    config = yaml.safe_load(f)\n\n# Load per-sensor mean/std used by AQI-36\nwith open(MEANSTD_PK, \"rb\") as f:\n    meanstd = pickle.load(f)\n\n# Adjust these depending on the exact structure\n#print(type(meanstd))\n#print(len(meanstd))\n#print(meanstd[0][:5])  # first 5 values of mean\n#print(meanstd[1][:5])  # first 5 values of std\n\nmean = np.asarray(meanstd[0], dtype=np.float32)\nstd  = np.asarray(meanstd[1], dtype=np.float32)\nstd_safe = np.where(std == 0, 1.0, std)\n\nwith open(CONFIG_PATH, \"r\") as f:\n    config = yaml.safe_load(f)\n\nconfig[\"model\"][\"is_unconditional\"] = False       \nconfig[\"model\"][\"target_strategy\"] = \"hybrid\"\nconfig[\"diffusion\"][\"adj_file\"] = \"AQI36\"        \nconfig[\"seed\"] = 42\n\nos.makedirs(\"./data/pm25/SampleData\", exist_ok=True)\nshutil.copy(\n    \"/kaggle/input/airq36/pm25/SampleData/pm25_latlng.txt\",\n    \"./data/pm25/SampleData/pm25_latlng.txt\"\n)\n\ndef scale_window(x_2d: np.ndarray) -> np.ndarray:\n    # x_2d shape: (T, N)\n    return (x_2d - mean) / std_safe\n\ndef inv_scale_vec(x_1d: np.ndarray) -> np.ndarray:\n    # x_1d shape: (N,)\n    return x_1d * std_safe + mean\n\n# Load PriSTI AQI-36 model\nmodel = PriSTI_aqi36(config, DEVICE).to(DEVICE)\nstate = torch.load(WEIGHTS_PATH, map_location=DEVICE)\nmodel.load_state_dict(state)\nmodel.eval()\nprint(\"PriSTI AQI-36 model loaded.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport json\n\n\nlatlng = pd.read_csv(\"/kaggle/input/airq36/pm25/SampleData/pm25_latlng.txt\")\nmissing_df_raw = pd.read_csv(\n    \"/kaggle/input/airq36/pm25/SampleData/pm25_missing.txt\",\n    index_col=\"datetime\", parse_dates=True\n)\nground_df = pd.read_csv(\n    \"/kaggle/input/airq36/pm25/SampleData/pm25_ground.txt\",\n    index_col=\"datetime\", parse_dates=True\n)\n\ndef normalize_cols(cols):\n    return (\n        pd.Index(cols)\n          .astype(str)\n          .str.strip()\n          .str.lstrip(\"0\")\n          .tolist()\n    )\n\nsensor_ids = normalize_cols(latlng[\"sensor_id\"])\nmissing_df_raw.columns = normalize_cols(missing_df_raw.columns)\nground_df.columns      = normalize_cols(ground_df.columns)\n\n# Reorder columns to match sensor_ids\nmissing_df_raw = missing_df_raw[sensor_ids]\nground_df      = ground_df[sensor_ids]\n\n#scaler params\nwith open(\"scaler_params.json\") as f:\n    sp = json.load(f)\n\nmin_val, max_val = sp[\"min_val\"], sp[\"max_val\"]\nscaler     = lambda x: (x - min_val) / (max_val - min_val)\ninv_scaler = lambda x: x * (max_val - min_val) + min_val\n\n#Mask building\ntry:\n    artificial_mask = pd.read_csv(\n        \"/kaggle/input/airq36/pm25/SampleData/artificial_mask.csv\",\n        index_col=\"datetime\", parse_dates=True\n    ).astype(bool)\n    artificial_mask = artificial_mask[sensor_ids]\nexcept FileNotFoundError:\n    artificial_mask = missing_df_raw.isna() & ground_df.notna()\n\n\nTEST_MONTHS = {3, 6, 9, 12}  \nmonth_mask = missing_df_raw.index.month.isin(TEST_MONTHS)\n\nmissing_df_raw = missing_df_raw.loc[month_mask]\nground_df      = ground_df.loc[month_mask]\nartificial_mask = artificial_mask.loc[month_mask]\n\nprint(f\"After month filter: {len(missing_df_raw)} timestamps remain\")\n\n#window with valid_ends (the ideat that we take only the windows where we have at least one artifical missed value in the last column)\nEVAL_LEN = 36\nT = len(missing_df_raw)\nvalid_ends = []\n\nfor t in range(EVAL_LEN - 1, T):\n    if artificial_mask.iloc[t].any():\n        valid_ends.append(t)\n\nprint(\"Number of valid test windows:\", len(valid_ends))\n\n\nclass PriSTITestDataset(Dataset):\n    def __init__(self, data_df, gt_df, ends, eval_len, scaler):\n        filled     = data_df.ffill().bfill()\n        self.data_np   = filled.to_numpy(dtype=np.float32)            # [T, N]\n        self.mask_np   = (~data_df.isna()).to_numpy(dtype=np.float32) # [T, N]\n        self.gt_np     = gt_df.fillna(0.0).to_numpy(dtype=np.float32) # [T, N]\n\n        self.scaled    = scaler(self.data_np)     # [T, N]\n        self.gt_scaled = scaler(self.gt_np)       # [T, N]\n\n        self.ends     = ends\n        self.eval_len = eval_len\n\n    def __len__(self):\n        return len(self.ends)\n\n    def __getitem__(self, idx):\n        end   = self.ends[idx]\n        start = end - (self.eval_len - 1)\n\n        window_x = self.scaled   [start : end+1]  # [T, N]\n        window_m = self.mask_np  [start : end+1]  # [T, N]\n        y_true   = self.gt_scaled[end]            # [N]\n\n        # Transpose to match PriSTI API: [N, T]\n        x = torch.from_numpy(window_x.T.copy())\n        m = torch.from_numpy(window_m.T.copy())\n        y = torch.from_numpy(y_true.copy())\n\n        return x, m, y\n\n\ntest_ds = PriSTITestDataset(\n    data_df   = missing_df_raw,\n    gt_df     = ground_df,\n    ends      = valid_ends,\n    eval_len  = EVAL_LEN,\n    scaler    = scaler\n)\n\ntorch.backends.cudnn.enabled = False\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n\nprint(\"Final dataset length:\", len(test_ds))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nimport time\nfrom tqdm import tqdm\n\nt0 = time.perf_counter()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device).eval()\n\nall_preds, all_truth, all_mask = [], [], []\n\nwith torch.no_grad():\n    for x_batch, m_batch, y_batch in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n        # Move to device\n        x_batch = x_batch.to(device)   \n        m_batch = m_batch.to(device)   \n        y_batch = y_batch.to(device)   \n\n        B, N, T = x_batch.shape\n        inner = getattr(model, \"model\", model)\n\n        # side_info\n        tp = torch.arange(T, device=device).unsqueeze(0).expand(B, -1)\n        side_info = inner.get_side_info(tp, m_batch)\n\n        itp_info = None\n        if getattr(inner, \"use_guide\", False):\n            itp_info = torch.zeros((B, 1, N, T), device=device, dtype=torch.float32)\n\n        # Model inference\n        y_pred = inner.impute(\n            x_batch, m_batch, side_info,\n            n_samples=10,\n            itp_info=itp_info\n        )\n\n        # Handle sample dimension if present\n        if y_pred.dim() == 4:\n            y_pred = y_pred.mean(dim=1)  # [B, N, T]\n\n        # Extract last time stamp values\n        last_scaled = y_pred[:, :, -1]                      # [B, N]\n        preds       = inv_scaler(last_scaled.cpu().numpy()) # [B, N]\n        truth       = inv_scaler(y_batch.cpu().numpy())     # [B, N]\n        mask_last   = m_batch[:, :, -1].cpu().numpy()       # [B, N]\n\n        all_preds.append(preds)\n        all_truth.append(truth)\n        all_mask.append(mask_last)\n\n# Stacking\nall_preds = np.vstack(all_preds)  # [num_windows, N]\nall_truth = np.vstack(all_truth)  # [num_windows, N]\nall_mask  = np.vstack(all_mask)   # [num_windows, N]\n\n# Evaluate only on artificially missing values\nmiss_pos = (all_mask == 0)\nmae  = mean_absolute_error(all_truth[miss_pos], all_preds[miss_pos])\nrmse = np.sqrt(mean_squared_error(all_truth[miss_pos], all_preds[miss_pos]))\n\nt1 = time.perf_counter()\nprint(f\"Total inference time: {t1 - t0:.3f} seconds\")\nprint(f\"PriSTI Test MAE:  {mae:.4f}\")\nprint(f\"PriSTI Test RMSE: {rmse:.4f}\")\n# if you are on cluster you have to return or write all the results you needed","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}